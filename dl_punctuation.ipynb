{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 문장 기호 자동 추가\n",
    "문장이 주어졌을 때 문장 부호인 마침표('.')와 쉼표(',') 를 자동으로 추가하는 프로그램을 작성하는 것을 목표로 한다.  \n",
    "이를 수행하기 위하여 복수의 문장을 입력 받아 Deep Learning Network 을 구성하여 training 하고,  \n",
    "주어진 문장에 대하여 적용하여 실제 동작을 잘 수행하는지 확인 한다  \n",
    "\n",
    "예를 들면, 아래와 같이 문장이 주어졌다고 가정하자.  \n",
    "```\n",
    "   \"오늘 걷지 않는다면 내일은 뛰어야 한다\"\n",
    "```\n",
    "우리가 원하는 결과는 아래와 같을 것이다.  \n",
    "```\n",
    "   \"오늘 걷지 않는다면, 내일은 뛰어야 한다.\"\n",
    "```\n",
    "  \n",
    "## overview\n",
    "\n",
    "입력된 문장에서 target 을 아래와 같이 구성한다  \n",
    "\n",
    "```\n",
    " 문자 : '<nop>'  \n",
    "   . : '.'  \n",
    "   , : ','  \n",
    "```\n",
    "\n",
    "즉, 위의 예를 다시 쓰면 아래처럼 될 것이다. \n",
    "```\n",
    "   오 : '<nop>'\n",
    "   늘 : '<nop>'\n",
    "      : '<nop>'\n",
    "   걷 : '<nop>'\n",
    "   ... \n",
    "   면 : '<nop>'\n",
    "   , : ','\n",
    "     : '<nop>'\n",
    "   내 : '<nop>'\n",
    "   일 : '<nop>'\n",
    "   ...\n",
    "   한 : '<nop>'\n",
    "   다 : '<nop>'\n",
    "   . : '.'\n",
    "```\n",
    "```\n",
    "\"오늘 걷지 않는다면, 내일은 뛰어야 한다.\"\n",
    "```\n",
    "가 들어오면, \n",
    "```\n",
    "<nop><nop><nop><nop><nop><nop><nop><nop><nop><nop>,<nop><nop><nop><nop><nop><nop>.\"\n",
    "```\n",
    "위와 같이 &lt;nop>, ',',  '.' 로 이루어진 리스트가 출력되는 문제로 추상화할 수 있다. \n",
    "즉, 각각의 character 하나마다, 3개의 class 중 하나의 값으로 분류하는 문제라고 볼 수 있다.  \n",
    "\n",
    "문장의 형태소 정보라든지 추가적인 정보를 사용한다면, 더 좋은 결과를 얻을 수 있을 것이라고 추측되나,  \n",
    "문제를 단순화 하기 위하여 문장을 문자 단위로 다루기로 한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in /home/nbcommon/anaconda3_410/lib/python3.5/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing \n",
    "\n",
    "입력은 한글로 된 세종 코퍼스 중 텍스트를 미리 다운 받아 처리하였다.  \n",
    "입력된 data 에서 $lt;body> 중 $lt;p> $lt;/p> 로 묶인 문장만을 사용하였다. \n",
    "  \n",
    "우선 trainging 을 위하여 입력한 data의 전처리가 필요하다.  \n",
    "문장을 입력받으면, 이에 대응하는 character vector 를 구성하여, input에 대한 dictionary 를 구성한다. \n",
    "한글의 문자는 그 수가 많고, 입력된 텍스트에는 영어나 특수 문자 등이 포함되었을 수 있으니,  \n",
    "모든 문자를 dictionary에 추가할 수는 없다.  \n",
    "그러므로 입력 문자의 빈도수를 보고 적절한 갯수로 입력 dictionary 의 크기를 제한한다. \n",
    "  \n",
    "아래는 입력된 문자에 대한 빈도수를 log scale 로 보여주는 그래프이다.  \n",
    "이 그래프를 참고하여 임의의 갯수로 dictionary 이 크기를 제한하여 진행하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of paragraph:  611\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEhCAYAAABhpec9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f558668dda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math, numpy as np, matplotlib.pyplot as plt\n",
    "import data\n",
    "\n",
    "rawdata = data.read_data(\"data/training/4BH00005.txt\")\n",
    "\n",
    "sorted_char_map = data.get_sorted_char_map(rawdata)\n",
    "\n",
    "plt.title('Frequency of Each Character', fontsize=18)\n",
    "plt.plot(np.array([math.log10(k[1]) for k in sorted_char_map]))\n",
    "plt.ylabel('$\\log_{10}$ Frequency', fontsize=14)\n",
    "plt.xlabel('Character Index', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 구성 \n",
    "\n",
    "입력은 임의로 정한 dictionary 중 하나이고,  \n",
    "이러한 입력이 들어올 때  \n",
    "출력은 세 개의 케이스 ('&lt;nop>', '.', ',') 중 하나를 출력하도록 하는 네트워크를 구성한다.  \n",
    "출력의 값이 존재하는 문제로 정의하였으므로,  \n",
    "supervised learning 으로 문제를 해결한다.  \n",
    "  \n",
    "문장을 training하여 문장 부호를 예측하는 모델에서  \n",
    "각 문장의 character 들은 그 이전에 나온 character와 밀접한 관계를 가지므로 \n",
    "이전 output 이 다음 step 의 input 으로 사용하는 네트워크인 Recurrent Neural Network 을 사용한다.  \n",
    "\n",
    "RNN 의 cell은 vanishing gradient 의 영향을 줄일 수 있는 LSTM 을 사용한다.  \n",
    "RNN 의 구성은 아래의 두 케이스를 진행하였다.  \n",
    "\n",
    "### Multilayer RNN \n",
    "Layer 를 2 layer를 사용하였고, hidden size 는 128 로 설정하였다.  \n",
    "각 cell 은 이전 cell 의 output 을 LSTM 의 input 으로 사용한다. \n",
    "100 개중 1 * 128 * 128 * 3 개중 1의 네트워크가 될 것이다. \n",
    "[그림]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNN \n",
    "테스트를 수행한 결과를 살펴보니, '.' 을 예측하는 과정에서, \n",
    "만약 아래와 같은 문장이 있을 때, \n",
    "```\n",
    "\"그가 방에 들어간다면\" \n",
    "```\n",
    "아래처럼 예측하는 경우를 볼 수 있었다. \n",
    "```\n",
    "\"그가 방에 들어간다.면\" \n",
    "```\n",
    "  \n",
    "앞의 문자들만을 고려하고 있어서 발생하는 현상이라고 판단되어, \n",
    "forward와 backward 를 모두 고려하는 Bidirectional RNN 을  \n",
    "사용하는 것이 정확도를 더 올릴 수 있을 것이라고 생각되어 이를 추가하였다.  \n",
    "Multilayer RNN에서도 두개의 cell 만을 사용하였으므로,  \n",
    "비교를 위해 Bidirectional 도 forward, backward 두 개의 cell 만을 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수행 결과 측정\n",
    "수행 결과를 측정한 지표로는 아래를 사용하였다. \n",
    "- loss \n",
    "training 시 결과로 리턴되는 값으로,  실측 data(target data)와 prediction 결과와의 차이를 나타낸다. \n",
    "- accuracy\n",
    "실측 data 와 prediction 의 결과로 각각 나온 list 를 비교하여 각 item 별로 비교하여,  \n",
    "같으면 true, 다르면 false 로 하여 이를 평균낸 값이다.  \n",
    "- speed \n",
    "수행 시간을 나타낸다.  \n",
    "- precision, recall, f-score\n",
    "전통적으로 NLP, 검색엔진 등의 성능을 측정하는 지표로 알려진 precision, recall, f-score 를 사용한다.  \n",
    "    - precision\n",
    "    prediction 한 결과 값 중 실제 data 와 일치하는 비율\n",
    "    - recall\n",
    "    실측 data 중 몇개가 prediction 과 일치하는지에 대한 비율\n",
    "    - f-score\n",
    "    precision 과 recall 을 하나의 지표로 표시하기 위한 목적으로 두 값의 조화평균\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "마침표의 경우 뚜렷한 패턴이 있으므로, 짧은 트레이닝 주기에서도 상당히 높은 예측률을 얻을 수 있었다. \n",
    "하지만 쉼표의 경우는 예측율이 낮았다. \n",
    "한국어에서 쉼표가 다양한 패턴으로 사용되고, 특히 명사의 나열과 같은 (ex> 사과, 포도, 배 등) 경우의 사용에서는 \n",
    "품사 정보가 있지 않다면, 예측을 하기 어려울 것으로 보인다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation \n",
    "### data preprocessing  과정 \n",
    "아래는 실제 data file 을 read 하여  \n",
    "character 에 대한 dictionary 를 구성하는 부분이다.  \n",
    "입력 dictionary 로는 100 개로 설정하였고, 출력은 '&lt;nop>, '.', ',' 3개 중 하나가 된다.   \n",
    "입력한 data 는 편의를 위하여 고정된 길이의 sequence length 로 나누어 저장한다.  \n",
    "이 sequence length 는 RNN 에서 몇개의 data 까지 고려할지를 결정하는 step 갯수의 값이 될 것이다.  \n",
    "각각 나눈 data 는 아래와 같은 종류로 전처리하여 저장한다. \n",
    "    - input data \n",
    "    고정길이로 나눈 문장에서 '.'과 ','를 삭제한 후 미리 구성한 dictionary 의 index 로 치환한다. \n",
    "    - target data \n",
    "    입력된 문장에 대한 실제 결과로, 입력된 문장을 '&lt;nop>', '.', ',' 로 변경한 결과를 저장한다.  \n",
    "    - sequence length \n",
    "    입력된 text 를 고정길이로 나누어 사용하여 필요가 없으나, 입력 문장에서 '.', ',' 를 strip 하는 과정을 거친 결과로,  \n",
    "    문장의 길이에 차이가 발생한다.  \n",
    "    이에 대응하기 위하여 input data 를 strip 한 길이를 저장하는 벡터가 필요하다.  \n",
    "    \n",
    "training 에 사용된 data 의 10프로는 overfitting을 방지하기 위하여 검증에 사용하도록,  \n",
    "preprocessing 한 dataset 을 training 용도와 validation 용도로 나누어 저장한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of paragraph:  50  characters:  8571\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "import utils\n",
    "import models.modelbase as base\n",
    "import time\n",
    "\n",
    "text = data.read_data(\"data/training/4BH00005.txt\", 50)\n",
    "# text = data.read_large_data(\"data/training\")\n",
    "\n",
    "dic_size = 100\n",
    "input_chars = data.make_input_dic(text, dic_size)\n",
    "output_chars = ['<nop>', '.', ',']\n",
    "\n",
    "char2vec = utils.Char2Vec(chars=input_chars, add_unknown=True)\n",
    "output_char2vec = utils.Char2Vec(chars=output_chars)\n",
    "input_size = char2vec.size\n",
    "output_size = output_char2vec.size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Variable 설정 \n",
    "input 은 입력 data 이고, target 은 Y 값, 즉 관측된 결과 값이다. \n",
    "seq_lens 는 입력 sequence 의 length 를 저장한다. \n",
    "  \n",
    "  \n",
    "이를 각각의 placeholder 로 설정한다. \n",
    "input 값에 대한 placeholder 는 3차원으로 아래와 같다.    \n",
    " [전체 batch size * sequence length * input size]    \n",
    "3번째 차원이 input size 인 이유는 one hot encoding 형식으로 데이터를 전달하려는 의도이다.  \n",
    "  \n",
    "출력 Y 는 one hot 이 아닌 index 로 저장할 예정이므로,  \n",
    "[전체 batch size * sequence length] 로 설정한다.  \n",
    "그 외 문장의 길이를 저장하는 sequence 에 대한 정보를 저장할 placeholder 를 설정한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# make and run multi layer LSTM network\n",
    "\n",
    "hidden_size = 128\n",
    "seq_length = 100\n",
    "modelconfig = base.ModelConfiguration(input_size, hidden_size, output_size, epoch=100)\n",
    "evals = {}\n",
    "types = [\"multi\", \"bimul\"]\n",
    "\n",
    "type = types[0]\n",
    "training_dataset, valid_dataset = data.make_sequences(text, char2vec, output_char2vec, seq_length)\n",
    "\n",
    "input_batch = training_dataset.input_batch\n",
    "target_batch = training_dataset.target_batch\n",
    "seq_lens = training_dataset.seq_lens\n",
    "\n",
    "hidden_size = modelconfig.hidden_size\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, seq_length])  # X data\n",
    "X_one_hot = tf.one_hot(X, modelconfig.input_size)  # one hot: 1 -> 0 1 0 0 0 0 0 0 0 0\n",
    "\n",
    "Y = tf.placeholder(tf.int32, [None, seq_length])  # Y label\n",
    "\n",
    "Seqlen = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네트워크 구성\n",
    "네트워크는 두 개의 종류로 설정하였다.  \n",
    "각 cell 은 128개의 hidden layer 로 구성하였다.  \n",
    "\n",
    "##### Multi layer \n",
    "1. 하나의 입력에 대하여 128개의 hidden layer 를 가진 LSTM cell 을 구성 \n",
    "2. 128 개의 입력을 받아 128개의 output 을 출력하는 layer 를 하나 더 구성 \n",
    "   1개의 layer 만을 사용할 경우 결과값의 성능이 떨어지므로, deep 하게 하나의 layer 를 더 구성한다. \n",
    "3. Dropout 설정 \n",
    "   overfitting 을 막기위하여 dropout 을 설정한다. dropout 은 training 시에 사용할 hidden layer 의 비율을 설정하는 것으로,  \n",
    "   전체를 사용하지 않으므로, overfitting 을 줄일 수 있다.  \n",
    "3. 128개의 hidden layer 에서 나온 output 을 3개의 class로 연결하는 네트워크 구성\n",
    "마지막 layer 와 연결되는 Weight 와 bias 를 직접 설정하여야 하나,  \n",
    "tensorflow 에서 tf.layers.dense() 라는 API 를 제공해 주므로,  \n",
    "이를 사용하여 마지막 layer 로 3개의 class 의 결과 layer 까지 구성된다. \n",
    "\n",
    "4. cost function 구성 \n",
    "이는 sparse_softmax_cross_entropy_with_logits 라는 tensorflow 의 API 를 사용하여 처리한다. \n",
    "\n",
    "우선 network 의 출력값, 즉 3개의 분류에 대한 score 가 나온 각 node 는 softmax 를 거친다. \n",
    "이를 거치면, 총합이 1이고, 각각은 0~1 사이로 대응되는 확률값으로 변경 가능하다.  \n",
    "\n",
    "network 의 출력값인 [x, y, z] 와 실제 label 값 [X, Y, Z] 를 비교하여, cost function 을 구성한다.  \n",
    "이를 위해 cross entroty 라는 방식을 사용한다.  \n",
    "logistic regressing 은 cross entropy 의 binary version 이라고 하는데,  \n",
    "계산식은 복잡하지 않으나, cross entroty 에 대한 의미에 대해서는 좀더 학습이 필요하다. \n",
    "  \n",
    "sparse 가 사용된 이유는 Y값이 1-hot 으로 구성되어 있지 않은데, 이를 자동으로 1-hot 으로 변경해주므로,  \n",
    "sparse 가 붙은 API 를 사용한다. \n",
    "  \n",
    "5. optimization  \n",
    "cost function 을 설정한 tensor 에 optimze 를 설정한다.  \n",
    "optimization 의 대표적인 예는 gradient decent 방식이다. \n",
    "여기서는 tensorflow 의 AdamOptimizer 를 사용하였다.  \n",
    "실제 구동하여 보면 GradientDescentOptimizer 보다 정확도의 각종 지표들이 높게 나옴을 알 수 있다.\n",
    "\n",
    "###prediction 은 rnnmodel 의 linear regression 결과에 3번째 값, \n",
    "즉, 마지막 hidden layer 의 출력값에 WX + b 의 결과로 나온 값을 사용한다.\n",
    "\n",
    "##### Bidirectional layer \n",
    "위와 동일하고, 1,2 번 과정만이 차이가 있다. \n",
    "한 layer 는 backward 로 output data 를 참고하고,  \n",
    "다른 layer 는 forward 로 output data 를 입력받는다. \n",
    "각 layer를 128개의 hidden layer 로 설정했으므로, \n",
    "이 과정을 가쳐 256 개의 output 이 나온다. \n",
    "이를 tensorflow 의 dense 함수를 이용하여 3개의 class 의 output 으로 네트워크를 구성한다.  \n",
    "그 다음 과정은 위와 같다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Bidirectional LSTM start ******\n"
     ]
    }
   ],
   "source": [
    "if type == \"multi\":\n",
    "    print('\\n****** MultiLayer LSTM start ******')\n",
    "\n",
    "    with tf.variable_scope('cell_def'):\n",
    "        cell1 = tf.nn.rnn_cell.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "        cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=keep_prob)\n",
    "        cell2 = tf.nn.rnn_cell.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "        cell2 = tf.nn.rnn_cell.DropoutWrapper(cell2, output_keep_prob=keep_prob)\n",
    "        multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
    "\n",
    "    with tf.variable_scope('rnn_def'):\n",
    "        outputs, _states = tf.nn.dynamic_rnn(\n",
    "            multi_cell, X_one_hot, dtype=tf.float32, sequence_length=Seqlen)\n",
    "\n",
    "elif type == \"bimul\":\n",
    "    print('\\n****** Bidirectional LSTM start ******')\n",
    "\n",
    "    with tf.variable_scope('cell_def'):\n",
    "        forward = tf.nn.rnn_cell.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "        forward = tf.nn.rnn_cell.DropoutWrapper(forward, output_keep_prob=keep_prob)\n",
    "        backward = tf.nn.rnn_cell.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "        backward = tf.nn.rnn_cell.DropoutWrapper(backward, output_keep_prob=keep_prob)\n",
    "\n",
    "    with tf.variable_scope('rnn_def'):\n",
    "        outputs, states = tf.nn.bidirectional_dynamic_rnn(forward, backward, inputs=X_one_hot, dtype=tf.float32,\n",
    "                                                          sequence_length=Seqlen)\n",
    "        outputs = tf.concat(values=outputs, axis=2)\n",
    "\n",
    "model = tf.layers.dense(outputs, modelconfig.output_size, activation=None)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "prediction = tf.argmax(model, axis=2)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training \n",
    "위에 구성한 tensor graph 를 training 해준다. \n",
    "optimizer 의 결과는,, 이고,  \n",
    "cost 의 결과는 .. 이다.  \n",
    "\n",
    "epoch 25 단위마다, training data 중 10프로로 미리 구성된 test data 를 사용하여,  \n",
    "현재 결과를 evaluation 한다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ Training ------------ \n",
      "Epoch: 0025   accuracy = 0.981250   cost = 0.179770 speed = 8.64 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_410/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nbuser/anaconda3_410/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050   accuracy = 0.981250   cost = 0.173911 speed = 8.67 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n",
      "Epoch: 0075   accuracy = 0.981250   cost = 0.167385 speed = 8.87 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n",
      "Epoch: 0100   accuracy = 0.981250   cost = 0.162147 speed = 8.38 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n",
      "0.981249988079\n",
      "8.640311241149902\n",
      "0.333333333333\n",
      "0.170803025365\n",
      "0.330171383675\n",
      "0.327083333333\n",
      "\n",
      "------------ Testing ------------ \n",
      "length of paragraph:  12  characters:  1535\n",
      "Accuracy = 0.980625\n",
      "target sentence:     글을 쓰는 것은 혼자만의 일이 아니었다. 한 문장을 쓸 때마다  마음 속에 자리잡고 있는 수많은 독자들의 눈이 나를 감시하였다. 그래서인지 이 책을  다 완성하였을 때 느낀 감정은  \n",
      "prediction sentence: 글을 쓰는 것은 혼자만의 일이 아니었다 한 문장을 쓸 때마다  마음 속에 자리잡고 있는 수많은 독자들의 눈이 나를 감시하였다 그래서인지 이 책을  다 완성하였을 때 느낀 감정은  \n",
      "target sentence:      탈고의 기쁨보다는 감시의 눈초리로부터 벗어났다는 해방감이었다. 사람들은 많은 생각을 갖고 있다. 보통 사람들의 머리 속에는  책 몇 권 분량에 해당하는 많은 생각이 들어 있다.    \n",
      "prediction sentence:  탈고의 기쁨보다는 감시의 눈초리로부터 벗어났다는 해방감이었다 사람들은 많은 생각을 갖고 있다 보통 사람들의 머리 속에는  책 몇 권 분량에 해당하는 많은 생각이 들어 있다    \n",
      "target sentence:      누구나 다른 사람들에게 해주고 싶은  저마다의 이야기가 있기 때문이다. 하지만 머리 속에 이야기를 간직하고 있을 때와 그  이야기를 글로 써야 될 때에는 엄청난 차이가 있다. 나  \n",
      "prediction sentence:  누구나 다른 사람들에게 해주고 싶은  저마다의 이야기가 있기 때문이다 하지만 머리 속에 이야기를 간직하고 있을 때와 그  이야기를 글로 써야 될 때에는 엄청난 차이가 있다 나  \n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "{'bimul': <utils.Evaluation object at 0x7ff9b39f7438>}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "eval = utils.Evaluation(type, modelconfig.epoch, 25)\n",
    "\n",
    "print('\\n------------ Training ------------ ')\n",
    "last_time = time.time()\n",
    "for epoch in range(modelconfig.epoch):\n",
    "\n",
    "    _, loss = sess.run([optimizer, cost], feed_dict={X: input_batch,\n",
    "                                                     Y: target_batch,\n",
    "                                                     Seqlen: seq_lens,\n",
    "                                                     keep_prob: 0.8})\n",
    "    if epoch % 25 == 24:\n",
    "        result = sess.run(prediction, feed_dict={X: valid_dataset.input_batch,\n",
    "                                                 Y: valid_dataset.target_batch,\n",
    "                                                 Seqlen: valid_dataset.seq_lens,\n",
    "                                                 keep_prob: 1})\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(result, tf.cast(Y, tf.int64)), tf.float32))\n",
    "        accuracy_ret = sess.run(accuracy, feed_dict={Y: valid_dataset.target_batch})\n",
    "        speed = time.time() - last_time\n",
    "        print('Epoch:', '%04d  ' % (epoch + 1),\n",
    "              'accuracy =', '{:.6f}  '.format(accuracy_ret),\n",
    "              'cost =', '{:.6f}'.format(loss),\n",
    "              'speed =', '{:.2f}'.format(speed), 'sec')\n",
    "        last_time = time.time()\n",
    "\n",
    "        avg_p, avg_r, avg_f = utils.print_evaluation(valid_dataset.target_batch, result, output_char2vec.char_dict)\n",
    "        eval.set(accuracy_ret, loss, speed, avg_p, avg_r, avg_f)\n",
    "        print('')\n",
    "eval_dict = eval.get_avg()\n",
    "\n",
    "print('\\n------------ Testing ------------ ')\n",
    "test_sentences = data.read_data(\"data/test/BHXX0035.txt\", 30)\n",
    "test_dataset, _ = data.make_sequences(test_sentences, char2vec, output_char2vec, seq_length,\n",
    "                                      make_valid=False)\n",
    "\n",
    "result = sess.run(prediction, feed_dict={X: test_dataset.input_batch,\n",
    "                                         Y: test_dataset.target_batch,\n",
    "                                         Seqlen: test_dataset.seq_lens,\n",
    "                                         keep_prob: 1})\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(result, tf.cast(Y, tf.int64)), tf.float32))\n",
    "accuracy_ret = sess.run(accuracy, feed_dict={Y: test_dataset.target_batch})\n",
    "\n",
    "print('Accuracy =', '{:.6f}'.format(accuracy_ret))\n",
    "\n",
    "for index, predict_sequence in enumerate(result):\n",
    "    target_output, prediction_output = data.compare_sentence(output_char2vec,\n",
    "                                                             test_dataset.target_batch[index],\n",
    "                                                             test_dataset.input_source[index],\n",
    "                                                             predict_sequence)\n",
    "    if index < 3:\n",
    "        print(\"target sentence:    \", target_output[1])\n",
    "        print(\"prediction sentence:\", prediction_output[1])\n",
    "\n",
    "avg_p, avg_r, avg_f = utils.print_evaluation(test_dataset.target_batch, result, output_char2vec.char_dict)\n",
    "\n",
    "evals[type] = eval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<stripped 6400 bytes>' has type str, but expected one of: bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-05763ab98063>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-86ed9391ff6a>\u001b[0m in \u001b[0;36mshow_graph\u001b[0;34m(graph_def, max_const_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'as_graph_def'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mstrip_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrip_consts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_const_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_const_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     code = \"\"\"\n\u001b[1;32m     22\u001b[0m         \u001b[0;34m<\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-86ed9391ff6a>\u001b[0m in \u001b[0;36mstrip_consts\u001b[0;34m(graph_def, max_const_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_const_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<stripped %d bytes>\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<stripped 6400 bytes>' has type str, but expected one of: bytes"
     ]
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing \n",
    "\n",
    "아래와 같이 training 에 사용하지 않고 따로 준비한 \n",
    "data 로 실제 training 결과를 성능 지표 및 실제 문장으로 출력해본다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentence = list(\"예를 들어, 이와 같은 경우 불법이 확실하다.\")\n",
    "test_dataset, _ = model.make_sequences(test_sentence, char2vec, output_char2vec, seq_length, make_valid=False)\n",
    "weights = model.make_weight_mat(test_dataset.input_batch, test_dataset.seq_lens)\n",
    "\n",
    "# print(test_dataset.input_batch)\n",
    "# print(test_dataset.target_batch)\n",
    "\n",
    "result = sess.run(prediction, feed_dict={X: test_dataset.input_batch, Y: test_dataset.target_batch,\n",
    "                                                   Weight: weights, Seqlen: test_dataset.seq_lens})\n",
    "# print(result)\n",
    "\n",
    "for index, sq in enumerate(result):\n",
    "    result_output, target_output = model.compare_sentence(output_char2vec, test_dataset.target_batch[index],\n",
    "                                                         test_dataset.input_source[index], sq, printable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "evaluation 는 sci-learn api 를 사용하였다. \n",
    "\n",
    "두 개를 비교해서 모델과 비교한 것이다.  \n",
    "\n",
    "입력 data 의 양을 늘려서 실제 수행해보도록 하겠다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Bidirectional LSTM Initialize ******\n",
      "------------ Training ------------ \n",
      "Epoch: 0025   accuracy = 0.981250   cost = 0.163670 speed = 8.62 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_410/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nbuser/anaconda3_410/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050   accuracy = 0.981250   cost = 0.141696 speed = 8.49 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n",
      "Epoch: 0075   accuracy = 0.981250   cost = 0.109152 speed = 8.95 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n",
      "Epoch: 0100   accuracy = 0.991250   cost = 0.062073 speed = 8.50 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m100.0\u001b[0m%\tRecall: \u001b[32m 87.5\u001b[0m%\tF-Score: \u001b[32m 91.7\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 99.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.6\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n",
      "1.96499997377\n",
      "17.28117734193802\n",
      "0.739583333333\n",
      "0.289950804785\n",
      "0.737150389622\n",
      "0.738325968013\n",
      "------------ Testing ------------ \n",
      "length of paragraph:  12  characters:  1535\n",
      "Accuracy = 0.989375\n",
      "target sentence:     글을 쓰는 것은 혼자만의 일이 아니었다. 한 문장을 쓸 때마다  마음 속에 자리잡고 있는 수많은 독자들의 눈이 나를 감시하였다. 그래서인지 이 책을  다 완성하였을 때 느낀 감정은  \n",
      "prediction sentence: 글을 쓰는 것은 혼자만의 일이 아니었다 한 문장을 쓸 때마다  마음 속에 자리잡고 있는 수많은 독자들의 눈이 나를 감시하였다 그래서인지 이 책을  다 완성하였을 때 느낀 감정은  \n",
      "target sentence:      탈고의 기쁨보다는 감시의 눈초리로부터 벗어났다는 해방감이었다. 사람들은 많은 생각을 갖고 있다. 보통 사람들의 머리 속에는  책 몇 권 분량에 해당하는 많은 생각이 들어 있다.    \n",
      "prediction sentence:  탈고의 기쁨보다는 감시의 눈초리로부터 벗어났다는 해방감이었다 사람들은 많은 생각을 갖고 있다. 보통 사람들의 머리 속에는  책 몇 권 분량에 해당하는 많은 생각이 들어 있다.    \n",
      "target sentence:      누구나 다른 사람들에게 해주고 싶은  저마다의 이야기가 있기 때문이다. 하지만 머리 속에 이야기를 간직하고 있을 때와 그  이야기를 글로 써야 될 때에는 엄청난 차이가 있다. 나  \n",
      "prediction sentence:  누구나 다른 사람들에게 해주고 싶은  저마다의 이야기가 있기 때문이다. 하지만 머리 속에 이야기를 간직하고 있을 때와 그  이야기를 글로 써야 될 때에는 엄청난 차이가 있다. 나  \n",
      "target sentence:     는 이번에 그 차이를 절감하였다. 내가 이 글을 쓰고 원고를 다듬으면서 절실하게 느낀 것은 나의 지식은 말할  것도 없고 그 얕은 지식과 생각을 표현하는 능력조차도 너무나 부족하다 \n",
      "prediction sentence: 는 이번에 그 차이를 절감하였다 내가 이 글을 쓰고 원고를 다듬으면서 절실하게 느낀 것은 나의 지식은 말할  것도 없고 그 얕은 지식과 생각을 표현하는 능력조차도 너무나 부족하다 \n",
      "target sentence:     는 사실이었다. 오로지 뻔뻔스러움만이 이 책을 완성시킬 수 있는 힘이 되었던 것 같다. 그러나 수십 번이나 중도에서 포기하고 싶었던 이 일을 수행한 본래의 까닭은 다른 데 있다.    \n",
      "prediction sentence: 는 사실이었다 오로지 뻔뻔스러움만이 이 책을 완성시킬 수 있는 힘이 되었던 것 같다. 그러나 수십 번이나 중도에서 포기하고 싶었던 이 일을 수행한 본래의 까닭은 다른 데 있다.    \n",
      "target sentence:     사람들이 `철학'이라는 학문에 대해서 너무나도 많은 편견을 가지고 있다는 사실이 내게 이 작업을 시작하도록 하였고, 또  중도에서 포기할 수 없도록 하였다. 철학이라는  말을 들으  \n",
      "prediction sentence: 사람들이 `철학'이라는 학문에 대해서 너무나도 많은 편견을 가지고 있다는 사실이 내게 이 작업을 시작하도록 하였고 또  중도에서 포기할 수 없도록 하였다 철학이라는  말을 들으  \n",
      "target sentence:     면 사람들은 제일 먼저 미아리 고개 근처의 점쟁이나 깊은 산 속에서 입산수도하고 나온 긴 수염을 기른 괴팍스러운 사람들을 떠올린다. 물리학이 자연의 물리현상을 다루는 학문이고, 경  \n",
      "prediction sentence: 면 사람들은 제일 먼저 미아리 고개 근처의 점쟁이나 깊은 산 속에서 입산수도하고 나온 긴 수염을 기른 괴팍스러운 사람들을 떠올린다 물리학이 자연의 물리현상을 다루는 학문이고 경  \n",
      "target sentence:     제학이 한 사회의 물질적 부를 다루는 학문인 것과 마찬가지로 철학도 하나의 `학문'이다. 물리학이나 경제학이 사람들의 삶을 윤택하게 만드는 데 도움을 주기  위해서 존재하듯이 철학 \n",
      "prediction sentence: 제학이 한 사회의 물질적 부를 다루는 학문인 것과 마찬가지로 철학도 하나의 `학문'이다. 물리학이나 경제학이 사람들의 삶을 윤택하게 만드는 데 도움을 주기  위해서 존재하듯이 철학 \n",
      "target sentence:     도 마찬가지의  이유에서 존재한다. 과학이나 경제학에서 엄밀하고 일관된 논리와 법칙이 필요하듯이 철학에서도 이러한 논리적 엄밀성이 요구된다. 단지, 철학이라는 학문의 대상은 자연의   \n",
      "prediction sentence: 도 마찬가지의  이유에서 존재한다. 과학이나 경제학에서 엄밀하고 일관된 논리와 법칙이 필요하듯이 철학에서도 이러한 논리적 엄밀성이 요구된다. 단지 철학이라는 학문의 대상은 자연의   \n",
      "target sentence:      물리현상이나 경제법칙 등 제한된 영역이 아니라 인간의 사고라는  포괄적이고 추상적인 측면이라는 차이가  있을 뿐이다. 철학은 여러 학문들로부터 열외된 `이상한 학문'이 결코 아니 \n",
      "prediction sentence:  물리현상이나 경제법칙 등 제한된 영역이 아니라 인간의 사고라는  포괄적이고 추상적인 측면이라는 차이가  있을 뿐이다. 철학은 여러 학문들로부터 열외된 `이상한 학문'이 결코 아니 \n",
      "target sentence:     다. 사람들의 오해를 불식시키고 철학의 필요성을 인식시켜주기 위해서 과감하게 용기를 내긴 하였지만 이 작업이 만족할 만한 것인지에 대해서는 여전히 자신이 생기지 않는다. 비록 마음  \n",
      "prediction sentence: 다 사람들의 오해를 불식시키고 철학의 필요성을 인식시켜주기 위해서 과감하게 용기를 내긴 하였지만 이 작업이 만족할 만한 것인지에 대해서는 여전히 자신이 생기지 않는다 비록 마음  \n",
      "target sentence:      속에 있던 독자들의 눈초리로부터 해방되기는 하였지만 이제 정작 이 책을 읽는 현실의 독자들이 내 앞에 가로서 있다는 사실도 엄청난 부담이  된다. 서툴고 난삽한 표현이 있더라도  \n",
      "prediction sentence:  속에 있던 독자들의 눈초리로부터 해방되기는 하였지만 이제 정작 이 책을 읽는 현실의 독자들이 내 앞에 가로서 있다는 사실도 엄청난 부담이  된다. 서툴고 난삽한 표현이 있더라도  \n",
      "target sentence:     독자들의 아량을 바란다. 혹 잘못된 곳이나 부족한 면이 있다면 개정판을 통해서 보충할 것이다. 비록 보잘 것 없는 책이긴 하지만, 이 책은 나 혼자의 힘으로 이루어진 것이 아니다.    \n",
      "prediction sentence: 독자들의 아량을 바란다 혹 잘못된 곳이나 부족한 면이 있다면 개정판을 통해서 보충할 것이다. 비록 보잘 것 없는 책이긴 하지만 이 책은 나 혼자의 힘으로 이루어진 것이 아니다.    \n",
      "target sentence:      기획에서부터 원고를 쓰는 데까지 많은  선후배와 동료들이 함께 작업하였다.  글의 구성부터 원고검토와 교열에 이르기까지 많은 부분에서 귀중한 조언을 해주신 분들께 이 기회를 빌어 \n",
      "prediction sentence:  기획에서부터 원고를 쓰는 데까지 많은  선후배와 동료들이 함께 작업하였다  글의 구성부터 원고검토와 교열에 이르기까지 많은 부분에서 귀중한 조언을 해주신 분들께 이 기회를 빌어 \n",
      "target sentence:     서 다시 한 번 깊은 감사를 드린다. 아울러 부족한  책을 흔쾌히 출간해준 도서출판 녹두에도 깊은 감사를 드린다. 부족하고 모자라는 책이지만 이『철학 이야기주머니』가 철학을 이해하  \n",
      "prediction sentence: 서 다시 한 번 깊은 감사를 드린다 아울러 부족한  책을 흔쾌히 출간해준 도서출판 녹두에도 깊은 감사를 드린다 부족하고 모자라는 책이지만 이『철학 이야기주머니』가 철학을 이해하  \n",
      "target sentence:     려는 사람들에게 작은 도움이라도 되었으면 하는 마음 간절하다.                                                                   \n",
      "prediction sentence: 려는 사람들에게 작은 도움이라도 되었으면 하는 마음 간절하다.                                                                   \n"
     ]
    }
   ],
   "source": [
    "import models.rnns as rnns\n",
    "bidir_rnn = rnns.MultiLayerLSTM(modelconfig, char2vec, output_char2vec, text, seq_length=100, type=\"bimul\")\n",
    "evals[types[1]] = bidir_rnn.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclution \n",
    "실제 수행결과 쉼표는 예측율이 떨어졌다.  \n",
    "이는 .... \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO \n",
    "\n",
    "1. 현재 성능은 고려하지 않았으나, 수행 성능 비교. \n",
    "    1. mini batch 사용 시 \n",
    "    2. 각각 모델의 성능 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference \n",
    "https://github.com/episodeyang/deep-auto-punctuation  \n",
    "https://github.com/ematvey/tensorflow-seq2seq-tutorials/blob/master/1-seq2seq.ipynb\n",
    "http://pythonkim.tistory.com/20\n",
    "http://mazdah.tistory.com/791\n",
    "https://stackoverflow.com/questions/36515202/why-is-the-cross-entropy-method-preferred-over-mean-squared-error-in-what-cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
