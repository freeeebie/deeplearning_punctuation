{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 문장 기호 자동 추가\n",
    "문장이 주어졌을 때 문장 부호인 마침표('.')와 쉼표(',') 를 자동으로 추가하는 프로그램을 작성하는 것을 목표로 한다.  \n",
    "이를 수행하기 위하여 복수의 문장을 입력 받아 Deep Learning Network 을 구성하여 training 하고,  \n",
    "주어진 문장에 대하여 적용하여 실제 동작을 잘 수행하는지 확인 한다  \n",
    "\n",
    "예를 들면, 아래와 같이 문장이 주어졌다고 가정하자.  \n",
    "```\n",
    "   \"오늘 걷지 않는다면 내일은 뛰어야 한다\"\n",
    "```\n",
    "우리가 원하는 결과는 아래와 같을 것이다.  \n",
    "```\n",
    "   \"오늘 걷지 않는다면, 내일은 뛰어야 한다.\"\n",
    "```\n",
    "  \n",
    "## overview\n",
    "\n",
    "입력된 문장에서 target 을 아래와 같이 구성한다  \n",
    "\n",
    "```\n",
    " 문자 : '<nop>'  \n",
    "   . : '.'  \n",
    "   , : ','  \n",
    "```\n",
    "\n",
    "즉, 위의 예를 다시 쓰면 아래처럼 될 것이다. \n",
    "```\n",
    "   오 : '<nop>'\n",
    "   늘 : '<nop>'\n",
    "      : '<nop>'\n",
    "   걷 : '<nop>'\n",
    "   ... \n",
    "   면 : '<nop>'\n",
    "   , : ','\n",
    "     : '<nop>'\n",
    "   내 : '<nop>'\n",
    "   일 : '<nop>'\n",
    "   ...\n",
    "   한 : '<nop>'\n",
    "   다 : '<nop>'\n",
    "   . : '.'\n",
    "```\n",
    "```\n",
    "\"오늘 걷지 않는다면, 내일은 뛰어야 한다.\"\n",
    "```\n",
    "가 들어오면, \n",
    "```\n",
    "<nop><nop><nop><nop><nop><nop><nop><nop><nop><nop>,<nop><nop><nop><nop><nop><nop>.\"\n",
    "```\n",
    "위와 같이 &lt;nop>, ',',  '.' 로 이루어진 리스트가 출력되는 문제로 추상화할 수 있다. \n",
    "즉, 각각의 character 하나마다, 3개의 class 중 하나의 값으로 분류하는 문제라고 볼 수 있다.  \n",
    "\n",
    "문장의 형태소 정보라든지 추가적인 정보를 사용한다면, 더 좋은 결과를 얻을 수 있을 것이라고 추측되나,  \n",
    "문제를 단순화 하기 위하여 문장을 문자 단위로 다루기로 한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz\n",
      "Building wheels for collected packages: termcolor\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/de/f7/bf/1bcac7bf30549e6a4957382e2ecab04c88e513117207067b03\n",
      "Successfully built termcolor\n",
      "Installing collected packages: termcolor\n",
      "Successfully installed termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing \n",
    "\n",
    "입력은 한글로 된 세종 코퍼스 중 텍스트를 미리 다운 받아 처리하였다.  \n",
    "입력된 data 에서 $lt;body> 중 $lt;p> $lt;/p> 로 묶인 문장만을 사용하였다. \n",
    "  \n",
    "우선 trainging 을 위하여 입력한 data의 전처리가 필요하다.  \n",
    "문장을 입력받으면, 이에 대응하는 character vector 를 구성하여, input에 대한 dictionary 를 구성한다. \n",
    "한글의 문자는 그 수가 많고, 입력된 텍스트에는 영어나 특수 문자 등이 포함되었을 수 있으니,  \n",
    "모든 문자를 dictionary에 추가할 수는 없다.  \n",
    "그러므로 입력 문자의 빈도수를 보고 적절한 갯수로 입력 dictionary 의 크기를 제한한다. \n",
    "  \n",
    "아래는 입력된 문자에 대한 빈도수를 log scale 로 보여주는 그래프이다.  \n",
    "이 그래프를 참고하여 임의의 갯수로 dictionary 이 크기를 제한하여 진행하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_410/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/home/nbuser/anaconda3_410/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of paragraph:  1104  characters:  190957\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEhCAYAAABhpec9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda27c8e828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math, numpy as np, matplotlib.pyplot as plt\n",
    "import data\n",
    "\n",
    "rawdata = data.read_data(\"data/training/4BH00005.txt\")\n",
    "\n",
    "sorted_char_map = data.get_sorted_char_map(rawdata)\n",
    "\n",
    "plt.title('Frequency of Each Character', fontsize=18)\n",
    "plt.plot(np.array([math.log10(k[1]) for k in sorted_char_map]))\n",
    "plt.ylabel('$\\log_{10}$ Frequency', fontsize=14)\n",
    "plt.xlabel('Character Index', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 구성 \n",
    "\n",
    "입력은 임의로 정한 dictionary 중 하나이고,  \n",
    "이러한 입력이 들어올 때  \n",
    "출력은 세 개의 케이스 ('&lt;nop>', '.', ',') 중 하나를 출력하도록 하는 네트워크를 구성한다.  \n",
    "출력의 값이 존재하는 문제로 정의하였으므로,  \n",
    "supervised learning 으로 문제를 해결한다.  \n",
    "  \n",
    "문장을 training하여 문장 부호를 예측하는 모델에서  \n",
    "각 문장의 character 들은 그 이전에 나온 character와 밀접한 관계를 가지므로 \n",
    "이전 output 이 다음 step 의 input 으로 사용하는 네트워크인 Recurrent Neural Network 을 사용한다.  \n",
    "\n",
    "RNN 의 cell은 vanishing gradient 의 영향을 줄일 수 있는 LSTM 을 사용한다.  \n",
    "RNN 의 구성은 아래의 두 케이스를 진행하였다.  \n",
    "\n",
    "### Multilayer RNN \n",
    "Layer 를 2 layer를 사용하였고, hidden size 는 128 로 설정하였다.  \n",
    "각 cell 은 이전 cell 의 output 을 LSTM 의 input 으로 사용한다. \n",
    "100 개중 1 * 128 * 128 * 3 개중 1의 네트워크가 될 것이다. \n",
    "[그림]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNN \n",
    "테스트를 수행한 결과를 살펴보니, '.' 을 예측하는 과정에서, \n",
    "만약 아래와 같은 문장이 있을 때, \n",
    "```\n",
    "\"그가 방에 들어간다면\" \n",
    "```\n",
    "아래처럼 예측하는 경우를 볼 수 있었다. \n",
    "```\n",
    "\"그가 방에 들어간다.면\" \n",
    "```\n",
    "  \n",
    "앞의 문자들만을 고려하고 있어서 발생하는 현상이라고 판단되어, \n",
    "forward와 backward 를 모두 고려하는 Bidirectional RNN 을  \n",
    "사용하는 것이 정확도를 더 올릴 수 있을 것이라고 생각되어 이를 추가하였다.  \n",
    "Multilayer RNN에서도 두개의 cell 만을 사용하였으므로,  \n",
    "비교를 위해 Bidirectional 도 forward, backward 두 개의 cell 만을 사용하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수행 결과 측정\n",
    "수행 결과를 측정한 지표로는 아래를 사용하였다. \n",
    "- loss \n",
    "training 시 결과로 리턴되는 값으로,  실측 data(target data)와 prediction 결과와의 차이를 나타낸다. \n",
    "- accuracy\n",
    "실측 data 와 prediction 의 결과로 각각 나온 list 를 비교하여 각 item 별로 비교하여,  \n",
    "같으면 true, 다르면 false 로 하여 이를 평균낸 값이다.  \n",
    "- speed \n",
    "수행 시간을 나타낸다.  \n",
    "- precision, recall, f-score\n",
    "전통적으로 NLP, 검색엔진 등의 성능을 측정하는 지표로 알려진 precision, recall, f-score 를 사용한다.  \n",
    "    - precision\n",
    "    prediction 한 결과 값 중 실제 data 와 일치하는 비율\n",
    "    - recall\n",
    "    실측 data 중 몇개가 prediction 과 일치하는지에 대한 비율\n",
    "    - f-score\n",
    "    precision 과 recall 을 하나의 지표로 표시하기 위한 목적으로 두 값의 조화평균\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "마침표의 경우 뚜렷한 패턴이 있으므로, 짧은 트레이닝 주기에서도 상당히 높은 예측률을 얻을 수 있었다. \n",
    "하지만 쉼표의 경우는 예측율이 낮았다. \n",
    "한국어에서 쉼표가 다양한 패턴으로 사용되고, 특히 명사의 나열과 같은 (ex> 사과, 포도, 배 등) 경우의 사용에서는 \n",
    "품사 정보가 있지 않다면, 예측을 하기 어려울 것으로 보인다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation \n",
    "### data preprocessing  과정 \n",
    "아래는 실제 data file 을 read 하여  \n",
    "character 에 대한 dictionary 를 구성하는 부분이다.  \n",
    "입력 dictionary 로는 100 개로 설정하였고, 출력은 '&lt;nop>, '.', ',' 3개 중 하나가 된다.   \n",
    "입력한 data 는 편의를 위하여 고정된 길이의 sequence length 로 나누어 저장한다.  \n",
    "이 sequence length 는 RNN 에서 몇개의 data 까지 고려할지를 결정하는 step 갯수의 값이 될 것이다.  \n",
    "각각 나눈 data 는 아래와 같은 종류로 전처리하여 저장한다. \n",
    "    - input data \n",
    "    고정길이로 나눈 문장에서 '.'과 ','를 삭제한 후 미리 구성한 dictionary 의 index 로 치환한다. \n",
    "    - target data \n",
    "    입력된 문장에 대한 실제 결과로, 입력된 문장을 '&lt;nop>', '.', ',' 로 변경한 결과를 저장한다.  \n",
    "    - sequence length \n",
    "    입력된 text 를 고정길이로 나누어 사용하여 필요가 없으나, 입력 문장에서 '.', ',' 를 strip 하는 과정을 거친 결과로,  \n",
    "    문장의 길이에 차이가 발생한다.  \n",
    "    이에 대응하기 위하여 input data 를 strip 한 길이를 저장하는 벡터가 필요하다.  \n",
    "    \n",
    "training 에 사용된 data 의 10프로는 overfitting을 방지하기 위하여 검증에 사용하도록,  \n",
    "preprocessing 한 dataset 을 training 용도와 validation 용도로 나누어 저장한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of paragraph:  50  characters:  8571\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "import utils\n",
    "import models.modelbase as base\n",
    "\n",
    "text = data.read_data(\"data/training/4BH00005.txt\", 50)\n",
    "# text = data.read_large_data(\"data/training\")\n",
    "\n",
    "dic_size = 100\n",
    "input_chars = data.make_input_dic(text, dic_size)\n",
    "output_chars = ['<nop>', '.', ',']\n",
    "\n",
    "char2vec = utils.Char2Vec(chars=input_chars, add_unknown=True)\n",
    "output_char2vec = utils.Char2Vec(chars=output_chars)\n",
    "input_size = char2vec.size\n",
    "output_size = output_char2vec.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Variable 설정 \n",
    "input 은 입력 data 이고, target 은 Y 값, 즉 관측된 결과 값이다. \n",
    "seq_lens 는 입력 sequence 의 length 를 저장한다. \n",
    "  \n",
    "  \n",
    "이를 각각의 placeholder 로 설정한다. \n",
    "input 값에 대한 placeholder 는 3차원으로 아래와 같다.    \n",
    " [전체 batch size * sequence length * input size]    \n",
    "3번째 차원이 input size 인 이유는 one hot encoding 형식으로 데이터를 전달하려는 의도이다.  \n",
    "  \n",
    "출력 Y 는 one hot 이 아닌 index 로 저장할 예정이므로,  \n",
    "[전체 batch size * sequence length] 로 설정한다.  \n",
    "그 외 문장의 길이를 저장하는 sequence 에 대한 정보를 저장할 placeholder 를 설정한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import models.modelbase as base\n",
    "\n",
    "# make and run multi layer LSTM network\n",
    "\n",
    "hidden_size = 128\n",
    "seq_length = 100\n",
    "modelconfig = base.ModelConfiguration(input_size, hidden_size, output_size, epoch=500)\n",
    "evals = {}\n",
    "types = [\"multi\", \"bimul\"]\n",
    "\n",
    "type = \"multi\"\n",
    "training_dataset, valid_dataset = data.make_sequences(text, char2vec, output_char2vec, seq_length)\n",
    "\n",
    "input_batch = training_dataset.input_batch\n",
    "target_batch = training_dataset.target_batch\n",
    "seq_lens = training_dataset.seq_lens\n",
    "\n",
    "hidden_size = modelconfig.hidden_size\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, seq_length])  # X data\n",
    "X_one_hot = tf.one_hot(X, modelconfig.input_size)  # one hot: 1 -> 0 1 0 0 0 0 0 0 0 0\n",
    "\n",
    "Y = tf.placeholder(tf.int32, [None, seq_length])  # Y label\n",
    "\n",
    "Sequences = tf.placeholder(tf.int32, [None])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 네트워크 구성\n",
    "네트워크는 두 개의 종류로 설정하였다.  \n",
    "각 cell 은 128개의 hidden layer 로 구성하였다.  \n",
    "\n",
    "##### Multi layer \n",
    "1. 하나의 입력에 대하여 128개의 hidden layer 를 가진 LSTM cell 을 구성 \n",
    "2. 128 개의 입력을 받아 128개의 output 을 출력하는 layer 를 하나 더 구성 \n",
    "   1개의 layer 만을 사용할 경우 결과값의 성능이 떨어지므로, deep 하게 하나의 layer 를 더 구성한다. \n",
    "3. Dropout 설정 \n",
    "   overfitting 을 막기위하여 dropout 을 설정한다. dropout 은 training 시에 사용할 hidden layer 의 비율을 설정하는 것으로,  \n",
    "   전체를 사용하지 않으므로, overfitting 을 줄일 수 있다.  \n",
    "3. 128개의 hidden layer 에서 나온 output 을 3개의 class로 연결하는 네트워크 구성\n",
    "마지막 layer 와 연결되는 Weight 와 bias 를 직접 설정하여야 하나,  \n",
    "tensorflow 에서 tf.layers.dense() 라는 API 를 제공해 주므로,  \n",
    "이를 사용하여 마지막 layer 로 3개의 class 의 결과 layer 까지 구성된다. \n",
    "\n",
    "4. cost function 구성 \n",
    "이는 sparse_softmax_cross_entropy_with_logits 라는 tensorflow 의 API 를 사용하여 처리한다. \n",
    "\n",
    "우선 network 의 출력값, 즉 3개의 분류에 대한 score 가 나온 각 node 는 softmax 를 거친다. \n",
    "이를 거치면, 총합이 1이고, 각각은 0~1 사이로 대응되는 확률값으로 변경 가능하다.  \n",
    "\n",
    "network 의 출력값인 [x, y, z] 와 실제 label 값 [X, Y, Z] 를 비교하여, cost function 을 구성한다.  \n",
    "이를 위해 cross entroty 라는 방식을 사용한다.  \n",
    "logistic regressing 은 cross entropy 의 binary version 이라고 하는데,  \n",
    "계산식은 복잡하지 않으나, cross entroty 에 대한 의미에 대해서는 좀더 학습이 필요하다. \n",
    "  \n",
    "sparse 가 사용된 이유는 Y값이 1-hot 으로 구성되어 있지 않은데, 이를 자동으로 1-hot 으로 변경해주므로,  \n",
    "sparse 가 붙은 API 를 사용한다. \n",
    "  \n",
    "5. optimization  \n",
    "cost function 을 설정한 tensor 에 optimze 를 설정한다.  \n",
    "optimization 의 대표적인 예는 gradient decent 방식이다. \n",
    "여기서는 tensorflow 의 AdamOptimizer 를 사용하였다.  \n",
    "실제 구동하여 보면 GradientDescentOptimizer 보다 정확도의 각종 지표들이 높게 나옴을 알 수 있다.\n",
    "\n",
    "###prediction 은 rnnmodel 의 linear regression 결과에 3번째 값, \n",
    "즉, 마지막 hidden layer 의 출력값에 WX + b 의 결과로 나온 값을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/rnn_multi.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Bidirectional layer \n",
    "위와 동일하고, 1,2 번 과정만이 차이가 있다. \n",
    "한 layer 는 backward 로 output data 를 참고하고,  \n",
    "다른 layer 는 forward 로 output data 를 입력받는다. \n",
    "각 layer를 128개의 hidden layer 로 설정했으므로, \n",
    "이 과정을 가쳐 256 개의 output 이 나온다. \n",
    "이를 tensorflow 의 dense 함수를 이용하여 3개의 class 의 output 으로 네트워크를 구성한다.  \n",
    "그 다음 과정은 위와 같다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/rnn_bi.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** MultiLayer LSTM start ******\n"
     ]
    }
   ],
   "source": [
    "if type == \"multi\":\n",
    "    print('\\n****** MultiLayer LSTM start ******')\n",
    "\n",
    "    with tf.variable_scope('cell_def'):\n",
    "        cell1 = tf.nn.rnn_cell.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "        cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=keep_prob)\n",
    "        cell2 = tf.nn.rnn_cell.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "        cell2 = tf.nn.rnn_cell.DropoutWrapper(cell2, output_keep_prob=keep_prob)\n",
    "        multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
    "\n",
    "    with tf.variable_scope('rnn_def'):\n",
    "        outputs, _states = tf.nn.dynamic_rnn(\n",
    "            multi_cell, X_one_hot, dtype=tf.float32, sequence_length=Sequences)\n",
    "\n",
    "elif type == \"bimul\":\n",
    "    print('\\n****** Bidirectional LSTM start ******')\n",
    "\n",
    "    with tf.variable_scope('cell_def'):\n",
    "        forward = tf.nn.rnn_cell.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "        forward = tf.nn.rnn_cell.DropoutWrapper(forward, output_keep_prob=keep_prob)\n",
    "        backward = tf.nn.rnn_cell.BasicLSTMCell(num_units=hidden_size, state_is_tuple=True)\n",
    "        backward = tf.nn.rnn_cell.DropoutWrapper(backward, output_keep_prob=keep_prob)\n",
    "\n",
    "    with tf.variable_scope('rnn_def'):\n",
    "        outputs, states = tf.nn.bidirectional_dynamic_rnn(forward, backward, inputs=X_one_hot, dtype=tf.float32,\n",
    "                                                          sequence_length=Sequences)\n",
    "        outputs = tf.concat(values=outputs, axis=2)\n",
    "\n",
    "model = tf.layers.dense(outputs, modelconfig.output_size, activation=None)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "prediction = tf.argmax(model, axis=2)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training \n",
    "위에 구성한 tensor graph 를 training 해준다. \n",
    "optimizer 의 결과는,, 이고,  \n",
    "cost 의 결과는 .. 이다.  \n",
    "\n",
    "epoch 25 단위마다, training data 중 10프로로 미리 구성된 test data 를 사용하여,  \n",
    "현재 결과를 evaluation 한다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ Training ------------ \n",
      "Epoch: 0025   accuracy = 0.981250   cost = 0.179770 speed = 8.64 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_410/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nbuser/anaconda3_410/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050   accuracy = 0.981250   cost = 0.173911 speed = 8.67 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n",
      "Epoch: 0075   accuracy = 0.981250   cost = 0.167385 speed = 8.87 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n",
      "Epoch: 0100   accuracy = 0.981250   cost = 0.162147 speed = 8.38 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n",
      "0.981249988079\n",
      "8.640311241149902\n",
      "0.333333333333\n",
      "0.170803025365\n",
      "0.330171383675\n",
      "0.327083333333\n",
      "\n",
      "------------ Testing ------------ \n",
      "length of paragraph:  12  characters:  1535\n",
      "Accuracy = 0.980625\n",
      "target sentence:     글을 쓰는 것은 혼자만의 일이 아니었다. 한 문장을 쓸 때마다  마음 속에 자리잡고 있는 수많은 독자들의 눈이 나를 감시하였다. 그래서인지 이 책을  다 완성하였을 때 느낀 감정은  \n",
      "prediction sentence: 글을 쓰는 것은 혼자만의 일이 아니었다 한 문장을 쓸 때마다  마음 속에 자리잡고 있는 수많은 독자들의 눈이 나를 감시하였다 그래서인지 이 책을  다 완성하였을 때 느낀 감정은  \n",
      "target sentence:      탈고의 기쁨보다는 감시의 눈초리로부터 벗어났다는 해방감이었다. 사람들은 많은 생각을 갖고 있다. 보통 사람들의 머리 속에는  책 몇 권 분량에 해당하는 많은 생각이 들어 있다.    \n",
      "prediction sentence:  탈고의 기쁨보다는 감시의 눈초리로부터 벗어났다는 해방감이었다 사람들은 많은 생각을 갖고 있다 보통 사람들의 머리 속에는  책 몇 권 분량에 해당하는 많은 생각이 들어 있다    \n",
      "target sentence:      누구나 다른 사람들에게 해주고 싶은  저마다의 이야기가 있기 때문이다. 하지만 머리 속에 이야기를 간직하고 있을 때와 그  이야기를 글로 써야 될 때에는 엄청난 차이가 있다. 나  \n",
      "prediction sentence:  누구나 다른 사람들에게 해주고 싶은  저마다의 이야기가 있기 때문이다 하지만 머리 속에 이야기를 간직하고 있을 때와 그  이야기를 글로 써야 될 때에는 엄청난 차이가 있다 나  \n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "{'bimul': <utils.Evaluation object at 0x7ff9b39f7438>}\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "eval = utils.Evaluation(type, modelconfig.epoch, 25)\n",
    "\n",
    "print('\\n------------ Training ------------ ')\n",
    "last_time = time.time()\n",
    "for epoch in range(modelconfig.epoch):\n",
    "\n",
    "    _, loss = sess.run([optimizer, cost], feed_dict={X: input_batch,\n",
    "                                                     Y: target_batch,\n",
    "                                                     Sequences: seq_lens,\n",
    "                                                     keep_prob: 0.8})\n",
    "    if epoch % 25 == 24:\n",
    "        result = sess.run(prediction, feed_dict={X: valid_dataset.input_batch,\n",
    "                                                 Y: valid_dataset.target_batch,\n",
    "                                                 Sequences: valid_dataset.seq_lens,\n",
    "                                                 keep_prob: 1})\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(result, tf.cast(Y, tf.int64)), tf.float32))\n",
    "        accuracy_ret = sess.run(accuracy, feed_dict={Y: valid_dataset.target_batch})\n",
    "        speed = time.time() - last_time\n",
    "        print('Epoch:', '%04d  ' % (epoch + 1),\n",
    "              'accuracy =', '{:.6f}  '.format(accuracy_ret),\n",
    "              'cost =', '{:.6f}'.format(loss),\n",
    "              'speed =', '{:.2f}'.format(speed), 'sec')\n",
    "        last_time = time.time()\n",
    "\n",
    "        avg_p, avg_r, avg_f = utils.print_evaluation(valid_dataset.target_batch, result, output_char2vec.char_dict)\n",
    "        eval.set(epoch, accuracy_ret, loss, speed, avg_p, avg_r, avg_f)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<stripped 6400 bytes>' has type str, but expected one of: bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-05763ab98063>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-86ed9391ff6a>\u001b[0m in \u001b[0;36mshow_graph\u001b[0;34m(graph_def, max_const_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'as_graph_def'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mgraph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mstrip_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrip_consts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_const_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_const_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     code = \"\"\"\n\u001b[1;32m     22\u001b[0m         \u001b[0;34m<\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-86ed9391ff6a>\u001b[0m in \u001b[0;36mstrip_consts\u001b[0;34m(graph_def, max_const_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_const_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<stripped %d bytes>\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<stripped 6400 bytes>' has type str, but expected one of: bytes"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing \n",
    "\n",
    "아래와 같이 training 에 사용하지 않고 따로 준비한 \n",
    "data 로 실제 training 결과를 성능 지표 및 실제 문장으로 출력해본다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('\\n------------ Testing ------------ ')\n",
    "test_sentences = data.read_data(\"data/test/BHXX0035.txt\", 30)\n",
    "test_dataset, _ = data.make_sequences(test_sentences, char2vec, output_char2vec, seq_length,\n",
    "                                      make_valid=False)\n",
    "\n",
    "result = sess.run(prediction, feed_dict={X: test_dataset.input_batch,\n",
    "                                         Y: test_dataset.target_batch,\n",
    "                                         Sequences: test_dataset.seq_lens,\n",
    "                                         keep_prob: 1})\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(result, tf.cast(Y, tf.int64)), tf.float32))\n",
    "accuracy_ret = sess.run(accuracy, feed_dict={Y: test_dataset.target_batch})\n",
    "\n",
    "print('Accuracy =', '{:.6f}'.format(accuracy_ret))\n",
    "\n",
    "for index, predict_sequence in enumerate(result):\n",
    "    target_output, prediction_output = data.compare_sentence(output_char2vec,\n",
    "                                                             test_dataset.target_batch[index],\n",
    "                                                             test_dataset.input_source[index],\n",
    "                                                             predict_sequence)\n",
    "    if index < 2:\n",
    "        print(\"target sentence:    \", target_output[1])\n",
    "        print(\"prediction sentence:\", prediction_output[1])\n",
    "\n",
    "avg_p, avg_r, avg_f = utils.print_evaluation(test_dataset.target_batch, result, output_char2vec.char_dict)\n",
    "\n",
    "evals[type] = eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "evaluation 는 sci-learn api 를 사용하였다. \n",
    "\n",
    "두 개를 비교해서 모델과 비교한 것이다.  \n",
    "\n",
    "입력 data 의 양을 늘려서 실제 수행해보도록 하겠다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Bidirectional LSTM Initialize ******\n",
      "------------ Training ------------ \n",
      "Epoch: 0025   accuracy = 0.981250   cost = 0.163670 speed = 8.62 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_410/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/nbuser/anaconda3_410/lib/python3.5/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050   accuracy = 0.981250   cost = 0.141696 speed = 8.49 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n",
      "Epoch: 0075   accuracy = 0.981250   cost = 0.109152 speed = 8.95 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 98.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.1\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n",
      "Epoch: 0100   accuracy = 0.991250   cost = 0.062073 speed = 8.50 sec\n",
      "Key: \u001b[31m  ,\u001b[0m\tPrec: \u001b[32m100.0\u001b[0m%\tRecall: \u001b[32m 87.5\u001b[0m%\tF-Score: \u001b[32m 91.7\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m  .\u001b[0m\tPrec: \u001b[32m 99.1\u001b[0m%\tRecall: \u001b[32m100.0\u001b[0m%\tF-Score: \u001b[32m 99.6\u001b[0m\u001b[0m\n",
      "Key: \u001b[31m<nop>\u001b[0m\tPrec: \u001b[32m  0.0\u001b[0m%\tRecall: \u001b[32m  0.0\u001b[0m%\tF-Score: \u001b[32m  0.0\u001b[0m\u001b[0m\n",
      "\n",
      "1.96499997377\n",
      "17.28117734193802\n",
      "0.739583333333\n",
      "0.289950804785\n",
      "0.737150389622\n",
      "0.738325968013\n",
      "------------ Testing ------------ \n",
      "length of paragraph:  12  characters:  1535\n",
      "Accuracy = 0.989375\n",
      "target sentence:     글을 쓰는 것은 혼자만의 일이 아니었다. 한 문장을 쓸 때마다  마음 속에 자리잡고 있는 수많은 독자들의 눈이 나를 감시하였다. 그래서인지 이 책을  다 완성하였을 때 느낀 감정은  \n",
      "prediction sentence: 글을 쓰는 것은 혼자만의 일이 아니었다 한 문장을 쓸 때마다  마음 속에 자리잡고 있는 수많은 독자들의 눈이 나를 감시하였다 그래서인지 이 책을  다 완성하였을 때 느낀 감정은  \n",
      "target sentence:      탈고의 기쁨보다는 감시의 눈초리로부터 벗어났다는 해방감이었다. 사람들은 많은 생각을 갖고 있다. 보통 사람들의 머리 속에는  책 몇 권 분량에 해당하는 많은 생각이 들어 있다.    \n",
      "prediction sentence:  탈고의 기쁨보다는 감시의 눈초리로부터 벗어났다는 해방감이었다 사람들은 많은 생각을 갖고 있다. 보통 사람들의 머리 속에는  책 몇 권 분량에 해당하는 많은 생각이 들어 있다.    \n",
      "target sentence:      누구나 다른 사람들에게 해주고 싶은  저마다의 이야기가 있기 때문이다. 하지만 머리 속에 이야기를 간직하고 있을 때와 그  이야기를 글로 써야 될 때에는 엄청난 차이가 있다. 나  \n",
      "prediction sentence:  누구나 다른 사람들에게 해주고 싶은  저마다의 이야기가 있기 때문이다. 하지만 머리 속에 이야기를 간직하고 있을 때와 그  이야기를 글로 써야 될 때에는 엄청난 차이가 있다. 나  \n",
      "target sentence:     는 이번에 그 차이를 절감하였다. 내가 이 글을 쓰고 원고를 다듬으면서 절실하게 느낀 것은 나의 지식은 말할  것도 없고 그 얕은 지식과 생각을 표현하는 능력조차도 너무나 부족하다 \n",
      "prediction sentence: 는 이번에 그 차이를 절감하였다 내가 이 글을 쓰고 원고를 다듬으면서 절실하게 느낀 것은 나의 지식은 말할  것도 없고 그 얕은 지식과 생각을 표현하는 능력조차도 너무나 부족하다 \n",
      "target sentence:     는 사실이었다. 오로지 뻔뻔스러움만이 이 책을 완성시킬 수 있는 힘이 되었던 것 같다. 그러나 수십 번이나 중도에서 포기하고 싶었던 이 일을 수행한 본래의 까닭은 다른 데 있다.    \n",
      "prediction sentence: 는 사실이었다 오로지 뻔뻔스러움만이 이 책을 완성시킬 수 있는 힘이 되었던 것 같다. 그러나 수십 번이나 중도에서 포기하고 싶었던 이 일을 수행한 본래의 까닭은 다른 데 있다.    \n",
      "target sentence:     사람들이 `철학'이라는 학문에 대해서 너무나도 많은 편견을 가지고 있다는 사실이 내게 이 작업을 시작하도록 하였고, 또  중도에서 포기할 수 없도록 하였다. 철학이라는  말을 들으  \n",
      "prediction sentence: 사람들이 `철학'이라는 학문에 대해서 너무나도 많은 편견을 가지고 있다는 사실이 내게 이 작업을 시작하도록 하였고 또  중도에서 포기할 수 없도록 하였다 철학이라는  말을 들으  \n",
      "target sentence:     면 사람들은 제일 먼저 미아리 고개 근처의 점쟁이나 깊은 산 속에서 입산수도하고 나온 긴 수염을 기른 괴팍스러운 사람들을 떠올린다. 물리학이 자연의 물리현상을 다루는 학문이고, 경  \n",
      "prediction sentence: 면 사람들은 제일 먼저 미아리 고개 근처의 점쟁이나 깊은 산 속에서 입산수도하고 나온 긴 수염을 기른 괴팍스러운 사람들을 떠올린다 물리학이 자연의 물리현상을 다루는 학문이고 경  \n",
      "target sentence:     제학이 한 사회의 물질적 부를 다루는 학문인 것과 마찬가지로 철학도 하나의 `학문'이다. 물리학이나 경제학이 사람들의 삶을 윤택하게 만드는 데 도움을 주기  위해서 존재하듯이 철학 \n",
      "prediction sentence: 제학이 한 사회의 물질적 부를 다루는 학문인 것과 마찬가지로 철학도 하나의 `학문'이다. 물리학이나 경제학이 사람들의 삶을 윤택하게 만드는 데 도움을 주기  위해서 존재하듯이 철학 \n",
      "target sentence:     도 마찬가지의  이유에서 존재한다. 과학이나 경제학에서 엄밀하고 일관된 논리와 법칙이 필요하듯이 철학에서도 이러한 논리적 엄밀성이 요구된다. 단지, 철학이라는 학문의 대상은 자연의   \n",
      "prediction sentence: 도 마찬가지의  이유에서 존재한다. 과학이나 경제학에서 엄밀하고 일관된 논리와 법칙이 필요하듯이 철학에서도 이러한 논리적 엄밀성이 요구된다. 단지 철학이라는 학문의 대상은 자연의   \n",
      "target sentence:      물리현상이나 경제법칙 등 제한된 영역이 아니라 인간의 사고라는  포괄적이고 추상적인 측면이라는 차이가  있을 뿐이다. 철학은 여러 학문들로부터 열외된 `이상한 학문'이 결코 아니 \n",
      "prediction sentence:  물리현상이나 경제법칙 등 제한된 영역이 아니라 인간의 사고라는  포괄적이고 추상적인 측면이라는 차이가  있을 뿐이다. 철학은 여러 학문들로부터 열외된 `이상한 학문'이 결코 아니 \n",
      "target sentence:     다. 사람들의 오해를 불식시키고 철학의 필요성을 인식시켜주기 위해서 과감하게 용기를 내긴 하였지만 이 작업이 만족할 만한 것인지에 대해서는 여전히 자신이 생기지 않는다. 비록 마음  \n",
      "prediction sentence: 다 사람들의 오해를 불식시키고 철학의 필요성을 인식시켜주기 위해서 과감하게 용기를 내긴 하였지만 이 작업이 만족할 만한 것인지에 대해서는 여전히 자신이 생기지 않는다 비록 마음  \n",
      "target sentence:      속에 있던 독자들의 눈초리로부터 해방되기는 하였지만 이제 정작 이 책을 읽는 현실의 독자들이 내 앞에 가로서 있다는 사실도 엄청난 부담이  된다. 서툴고 난삽한 표현이 있더라도  \n",
      "prediction sentence:  속에 있던 독자들의 눈초리로부터 해방되기는 하였지만 이제 정작 이 책을 읽는 현실의 독자들이 내 앞에 가로서 있다는 사실도 엄청난 부담이  된다. 서툴고 난삽한 표현이 있더라도  \n",
      "target sentence:     독자들의 아량을 바란다. 혹 잘못된 곳이나 부족한 면이 있다면 개정판을 통해서 보충할 것이다. 비록 보잘 것 없는 책이긴 하지만, 이 책은 나 혼자의 힘으로 이루어진 것이 아니다.    \n",
      "prediction sentence: 독자들의 아량을 바란다 혹 잘못된 곳이나 부족한 면이 있다면 개정판을 통해서 보충할 것이다. 비록 보잘 것 없는 책이긴 하지만 이 책은 나 혼자의 힘으로 이루어진 것이 아니다.    \n",
      "target sentence:      기획에서부터 원고를 쓰는 데까지 많은  선후배와 동료들이 함께 작업하였다.  글의 구성부터 원고검토와 교열에 이르기까지 많은 부분에서 귀중한 조언을 해주신 분들께 이 기회를 빌어 \n",
      "prediction sentence:  기획에서부터 원고를 쓰는 데까지 많은  선후배와 동료들이 함께 작업하였다  글의 구성부터 원고검토와 교열에 이르기까지 많은 부분에서 귀중한 조언을 해주신 분들께 이 기회를 빌어 \n",
      "target sentence:     서 다시 한 번 깊은 감사를 드린다. 아울러 부족한  책을 흔쾌히 출간해준 도서출판 녹두에도 깊은 감사를 드린다. 부족하고 모자라는 책이지만 이『철학 이야기주머니』가 철학을 이해하  \n",
      "prediction sentence: 서 다시 한 번 깊은 감사를 드린다 아울러 부족한  책을 흔쾌히 출간해준 도서출판 녹두에도 깊은 감사를 드린다 부족하고 모자라는 책이지만 이『철학 이야기주머니』가 철학을 이해하  \n",
      "target sentence:     려는 사람들에게 작은 도움이라도 되었으면 하는 마음 간절하다.                                                                   \n",
      "prediction sentence: 려는 사람들에게 작은 도움이라도 되었으면 하는 마음 간절하다.                                                                   \n"
     ]
    }
   ],
   "source": [
    "import models.rnns as rnns\n",
    "\n",
    "bidir_rnn = rnns.MultiLayerLSTM(modelconfig, char2vec, output_char2vec, text, seq_length=100, type=\"bimul\")\n",
    "evals[types[1]] = bidir_rnn.run()\n",
    "\n",
    "import math, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "keys =list(evals[\"multi\"].total.keys())\n",
    "subplotnum = 321\n",
    "\n",
    "multi_eval = evals[\"multi\"].total\n",
    "bimul_eval = evals[\"bimul\"].total\n",
    "small = 12\n",
    "very_small = 10\n",
    "for key in keys:\n",
    "    plt.subplot(subplotnum)\n",
    "    plt.title(key, fontsize=small)\n",
    "\n",
    "    plt.plot([k[0] for k in multi_eval[key]], [k[1] for k in multi_eval[key]], label='multi')\n",
    "    plt.plot([k[0] for k in bimul_eval[key]], [k[1] for k in bimul_eval[key]], label='bidir')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel(key, fontsize=very_small)\n",
    "    plt.xlabel('Epoch', fontsize=very_small)\n",
    "    subplotnum = subplotnum + 1\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclution \n",
    "실제 수행결과 쉼표는 예측율이 떨어졌다.  \n",
    "이는 .... \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO \n",
    "\n",
    "1. 현재 성능은 고려하지 않았으나, 수행 성능 비교. \n",
    "    1. mini batch 사용 시 \n",
    "    2. 각각 모델의 성능 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference \n",
    "https://github.com/episodeyang/deep-auto-punctuation  \n",
    "https://github.com/ematvey/tensorflow-seq2seq-tutorials/blob/master/1-seq2seq.ipynb\n",
    "http://pythonkim.tistory.com/20\n",
    "http://mazdah.tistory.com/791\n",
    "https://stackoverflow.com/questions/36515202/why-is-the-cross-entropy-method-preferred-over-mean-squared-error-in-what-cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
